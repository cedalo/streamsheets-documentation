"use strict";(self.webpackChunkstreamsheets=self.webpackChunkstreamsheets||[]).push([[97964],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>c});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),u=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},m=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),d=u(n),c=o,h=d["".concat(l,".").concat(c)]||d[c]||p[c]||r;return n?a.createElement(h,i(i({ref:t},m),{},{components:n})):a.createElement(h,i({ref:t},m))}));function c(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var u=2;u<r;u++)i[u]=n[u];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},90377:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>k,contentTitle:()=>c,default:()=>f,frontMatter:()=>d,metadata:()=>h,toc:()=>g});var a=n(3905),o=Object.defineProperty,r=Object.defineProperties,i=Object.getOwnPropertyDescriptors,s=Object.getOwnPropertySymbols,l=Object.prototype.hasOwnProperty,u=Object.prototype.propertyIsEnumerable,m=(e,t,n)=>t in e?o(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,p=(e,t)=>{for(var n in t||(t={}))l.call(t,n)&&m(e,n,t[n]);if(s)for(var n of s(t))u.call(t,n)&&m(e,n,t[n]);return e};const d={id:"high-availability-autoscaling",title:"High Availability Autoscaling",sidebar_label:"High Availability Autoscaling"},c=void 0,h={unversionedId:"kubernetes/high-availability-autoscaling",id:"version-2.8/kubernetes/high-availability-autoscaling",title:"High Availability Autoscaling",description:"To set up a multi-node-HA Mosquitto broker and Management Center with autoscaling using Helm charts, you'll first need a Kubernetes environment. For deploying a full fledged kubernetes cluster on multiple hosts, Kubeadm is an excellent choice. Kubeadm is a command-line tool in the Kubernetes ecosystem designed to facilitate the process of setting up and bootstrapping a Kubernetes cluster.(Discussed in Introduction section).",source:"@site/mosquitto_versioned_docs/version-2.8/kubernetes/high-availability-autoscaling.md",sourceDirName:"kubernetes",slug:"/kubernetes/high-availability-autoscaling",permalink:"/mosquitto/2.8/kubernetes/high-availability-autoscaling",draft:!1,tags:[],version:"2.8",frontMatter:{id:"high-availability-autoscaling",title:"High Availability Autoscaling",sidebar_label:"High Availability Autoscaling"},sidebar:"someSidebar",previous:{title:"High Availability",permalink:"/mosquitto/2.8/kubernetes/high-availability"},next:{title:"Introduction",permalink:"/mosquitto/2.8/openshift/introduction"}},k={},g=[{value:"Why Auto-scaling ?",id:"why-auto-scaling-",level:3},{value:"How does Auto-scaling works?",id:"how-does-auto-scaling-works",level:3},{value:"Kubernetes Cluster Setup",id:"kubernetes-cluster-setup",level:2},{value:"Dependencies and Prerequisites",id:"dependencies-and-prerequisites",level:3},{value:"Installation",id:"installation",level:2},{value:"Installation using Helm Charts:",id:"installation-using-helm-charts",level:3},{value:"Further Useful Commands:",id:"further-useful-commands",level:3},{value:"Create Cluster in Management Center",id:"create-cluster-in-management-center",level:2},{value:"Connect to cluster",id:"connect-to-cluster",level:2},{value:"Usage",id:"usage",level:2}],N={toc:g};function f(e){var t,n=e,{components:o}=n,m=((e,t)=>{var n={};for(var a in e)l.call(e,a)&&t.indexOf(a)<0&&(n[a]=e[a]);if(null!=e&&s)for(var a of s(e))t.indexOf(a)<0&&u.call(e,a)&&(n[a]=e[a]);return n})(n,["components"]);return(0,a.kt)("wrapper",(t=p(p({},N),m),r(t,i({components:o,mdxType:"MDXLayout"}))),(0,a.kt)("p",null,"To set up a multi-node-HA Mosquitto broker and Management Center with autoscaling using Helm charts, you'll first need a Kubernetes environment. For deploying a full fledged kubernetes cluster on multiple hosts, Kubeadm is an excellent choice. Kubeadm is a command-line tool in the Kubernetes ecosystem designed to facilitate the process of setting up and bootstrapping a Kubernetes cluster.(Discussed in Introduction section).\nThis setup would deploy a 3 Mosquitto broker as a statefulsets. Also, a Management-Center pod and HA-proxy pod as a deployment entity. All the deployment would be deployed on multiple hosts. This deployment by default uses a NFS server to mount volumes. You would need to setup the NFS server before using this deployment."),(0,a.kt)("h3",p({},{id:"why-auto-scaling-"}),"Why Auto-scaling ?"),(0,a.kt)("p",null,"When we deploy the Kubernetes setup using the above procedure, by default we start with 3 Mosquitto Pods, 1 MMC and 1 HA. However, we might run into problems if we have a lot of incoming requests and connections causing overload at Mosquitto brokers, especially in DynSec mode. We would want the setup to adjust based on the load to avoid crashes and maintain system requirements and at the same time avoid any need of human monitoring and intervention."),(0,a.kt)("h3",p({},{id:"how-does-auto-scaling-works"}),"How does Auto-scaling works?"),(0,a.kt)("p",null,"On deploying the above setup we also deploy certain other helper pods that takes care of Auto-scaling. For eg:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Metrics Server:")," This server pod monitors metrics of the deployed applications pods. Metrics could be CPU, Memory etc."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Horizontal Pod Scaler (HPA):")," HPA automatically scales up or down the pods based on the threshold. For eg: If the CPU threshold is set to 60%, and of overall CPU consumption across all pods reaches 60%, HPA scales up the Mosquitto pods."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Cluster-operator:")," This pod keeps tracks of pod scaling and triggers the requests to MQTT APIs so that newly scaled pods gets added to internal cluster of Mosquitto brokers. For eg If the current number of Mosquitto brokers are 3 and it scales to 5, then cluster-operator would send a ",(0,a.kt)("inlineCode",{parentName:"li"},"addNode")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"joinCluster")," MQTT request for 2 added nodes. If pod is to be scaled down, then the cluster-operator would send ",(0,a.kt)("inlineCode",{parentName:"li"},"removeNode")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"leaveCluster")," MQTT API requests.")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Recommended Setup")),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"1 Control-plane node, 3 worker nodes and a NFS Server"),(0,a.kt)("li",{parentName:"ol"},"Management center (MMC) is configured to have a node affinity that means the pod for MMC will spawn on a specific worker node. The default configuration expects names of the worker  nodes to be ",(0,a.kt)("inlineCode",{parentName:"li"},"node-1"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"node-2")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"node-3"),". Given the nodes are named in similar fashion, MMC would be spawned on ",(0,a.kt)("inlineCode",{parentName:"li"},"node-1"),". "),(0,a.kt)("li",{parentName:"ol"},"If you want to have different names for your nodes you can also do that. You will have to adjust the hostnames of nodes in helm chart so that the MMC node affinity remains intact. To adjust the helm chart you will have to uncompress the helm charts and change the hostnames entries of ",(0,a.kt)("inlineCode",{parentName:"li"},"values.yaml"),". You can do so using the following command:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"tar -xzvf mosquitto-multi-node-multi-host-autoscale-0.1.0.tgz")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cd mosquitto-multi-node-multi-host-autoscale")),(0,a.kt)("li",{parentName:"ul"},"Change the values of hostname from ",(0,a.kt)("inlineCode",{parentName:"li"},"node-1/node-2/node-3"),"  to the names of your machines. For eg, ",(0,a.kt)("inlineCode",{parentName:"li"},"node-1"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"node-2"),"and ",(0,a.kt)("inlineCode",{parentName:"li"},"node-3")," can be renamed as ",(0,a.kt)("inlineCode",{parentName:"li"},"worker-node-1"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"worker-node-2")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"worker-node-3"),". Doing this, MMC would now be spawned on the node named ",(0,a.kt)("inlineCode",{parentName:"li"},"worker-node-1"),"."),(0,a.kt)("li",{parentName:"ul"},"Go back to the parent directory: ",(0,a.kt)("inlineCode",{parentName:"li"},"cd ../")),(0,a.kt)("li",{parentName:"ul"},"Package the helm chart to its original form using:\n",(0,a.kt)("inlineCode",{parentName:"li"},"helm package mosquitto-multi-node-multi-host-autoscale"))))),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"HA-PROXY Configurations"),"\nHA-proxy need to be configured accordingly for the kubernetes setup. For eg server m1, m2 and m3 needs to be configured in this case. You would need to configure more server based on your requirements and based on the number mounts you have created on NFS. The autoscaling setup may scale up and down your deployment, so make sure you setup atleast 6 server entries in your ",(0,a.kt)("inlineCode",{parentName:"p"},"haproxy.cfg"),". Instead of using docker IP we would use DNS names to address the pods. For eg\n",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-0.mosquitto.multinode.svc.cluster.local"),". Here ",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-0"),",",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-1"),",",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-2")," are the name of individual mosquitto pods running as statefulsets. Each new pod would increase its pod-ordinal by 1. Template of the connection endpoints can be defined as follows\n",(0,a.kt)("inlineCode",{parentName:"p"},"<pod-name>.<name-of-the-statefulset>.<namespace>.svc.cluster.local"),'\nYour setup folder comes along with a default configuration of haproxy config which is given below. This assumes that your using namespace name as "multinode". You can also change the namespace name if you want and the procedure to do it would be discussed at a later stage.\nIn the below config, we have configured 6 servers:'),(0,a.kt)("pre",null,(0,a.kt)("code",p({parentName:"pre"},{}),"global\n    daemon\n    maxconn 10000\n    resolvers kubernetes\n        nameserver dns1 10.96.0.10:53   # Replace with your Kube DNS IP\n        resolve_retries 3\n        timeout retry 1s\n        hold valid 10s\n\nfrontend mqtt_frontend\n    bind *:1883\n    mode tcp\n    default_backend mqtt_backend\n    timeout client 10m\n\nbackend mqtt_backend\n    timeout connect 5000\n    timeout server 10m\n    mode tcp\n    option redispatch\n    server m1 mosquitto-0.mosquitto.multinode.svc.cluster.local:1883 check resolvers kubernetes on-marked-down shutdown-sessions\n    server m2 mosquitto-1.mosquitto.multinode.svc.cluster.local:1883 check resolvers kubernetes on-marked-down shutdown-sessions\n    server m3 mosquitto-2.mosquitto.multinode.svc.cluster.local:1883 check resolvers kubernetes on-marked-down shutdown-sessions\n    server m4 mosquitto-3.mosquitto.multinode.svc.cluster.local:1883 check resolvers kubernetes on-marked-down shutdown-sessions\n    server m5 mosquitto-4.mosquitto.multinode.svc.cluster.local:1883 check resolvers kubernetes on-marked-down shutdown-sessions\n    server m6 mosquitto-5.mosquitto.multinode.svc.cluster.local:1883 check resolvers kubernetes on-marked-down shutdown-sessions\n")),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"10.96.0.10")," is the Kube-api server IP. We add nameserver so that the HA-proxy do not crash when some of the servers are not available as in autoscaling the pods server may scale up and down."),(0,a.kt)("h2",p({},{id:"kubernetes-cluster-setup"}),"Kubernetes Cluster Setup"),(0,a.kt)("h3",p({},{id:"dependencies-and-prerequisites"}),"Dependencies and Prerequisites"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Docker"),(0,a.kt)("li",{parentName:"ul"},"Kubernetes Cluster with Kubeadm"),(0,a.kt)("li",{parentName:"ul"},"Helm")),(0,a.kt)("p",null,"If you need to set up a Kubernetes cluster, you can refer to our installation script. If you plan on using your own cluster, you can skip to step 5. Follow these steps on your master/control-plane node :"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Setup the ha-cluster setups folder:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Copy or setup the ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling")," folder to the Control-plane node. Also make sure to create a directory inside the copied folder  on Control plane node named ",(0,a.kt)("inlineCode",{parentName:"li"},"license")," that contains the ",(0,a.kt)("inlineCode",{parentName:"li"},"license.lic")," file we provided you. So the relative path would be ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/license/license.lic"),"."))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Choose Architecture Folder:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Depending on your host architecture, navigate to the corresponding folder:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"For Debian AMD64:",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",p({parentName:"pre"},{className:"language-bash"}),"cd mosquitto-2.7-mmc-2.7-cluster-kubernetes-autoscaling/kubernetes/multi-node-multi-host-autoscaling/debian_amd64\n"))))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Install Common Dependencies:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Run the following command to install the necessary dependencies on all the nodes(including control-plane node):",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",p({parentName:"pre"},{className:"language-bash"}),"bash common-installation-debian.sh\n"))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Install Master Dependencies:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Run the following command to install the necessary dependencies on the master node:",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",p({parentName:"pre"},{className:"language-bash"}),"bash  master-installation-debian.sh\n"))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Create a namespace")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"On your Control-Plane node:")," Create a namespace in which you would want to deploy the application. The deployment folder is pre-configured for the namespace named ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode"),". If you want to use the default configuration you can create a namespace named ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," using the below command:"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"kubectl create namespace multinode")),(0,a.kt)("li",{parentName:"ul"},"If you want to use a different namespace, use the command: ",(0,a.kt)("inlineCode",{parentName:"li"},"kubectl create namespace <your-custom-namespace>"),".  Replace ",(0,a.kt)("inlineCode",{parentName:"li"},"<your-custom-namespace>")," with the name of the namespace you want to configure."))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Create configmap for your license")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"On your Control-Plane node:")," Create a configmap for your license key (same license you created ). You can create the configmap using the following command:"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"kubectl create configmap mosquitto-license -n <namespace> --from-file=<path-to-your-license-file>")),(0,a.kt)("li",{parentName:"ul"},"Make sure the name of the configmap remains the same as  ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-license")," as this is required by the deployment files and statefulsets."),(0,a.kt)("li",{parentName:"ul"},"A sample configmap creation command would look something like this if the choosen namespace is ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," and the license file is at the path ",(0,a.kt)("inlineCode",{parentName:"li"},"/root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/license/license.lic")," :",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"kubectl create configmap mosquitto-license -n multinode --from-file=/root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/license/license.lic"),"."))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Setup NFS Server")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Copy or setup the ",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling")," folder to the NFS-Server.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Install necessary dependencies\n",(0,a.kt)("inlineCode",{parentName:"p"},"sudo apt-get update"),"\n",(0,a.kt)("inlineCode",{parentName:"p"},"sudo apt-get install nfs-kernel-server"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Configure exports directory.Open the ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/exports")," file on NFS-server. Expose the directories so that pods running on other worker nodes can access these directories and mount the volumes."),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"The default starting point of the cluster is with 3 mosquitto broker nodes, however we will configure and expose a total of 6 mosquitto data directories along with a MMC config driectory in the NFS server. As the provisioning of data directories on the NFS servers are not dyanmic at the moment, configuring three extra mosquitto data directories allows the autoscaling to scale up till 6 pods seamlessly.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"The helm charts therefore is also configured in a fashion that they create total of 7 persistent volumes and persistent volume claims (6 for mosquitto data directories and 1 for MMC). However, only three mosquitto broker would be spinned up by default.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"You can use the following as a reference. Here we expose six mosquitto nodes and management center and the ",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling")," resides at ",(0,a.kt)("inlineCode",{parentName:"p"},"/root")," on our NFS server."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",p({parentName:"pre"},{})," /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server1/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server2/mosquitto/data  *(rw,sync,no_root_squash,no_subtree_check)\n /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server3/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server4/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server5/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server6/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server1/management-center/config *(rw,sync,no_root_squash,no_subtree_check)\n"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Make sure all the data directories have adequate privileges so that mosquitto kubernetes pods can create additional directories inside these data directories. We provide 1000 ownership to all the data directory of mosquitto servers and root ownership to config of management-center. The same ownership are also the default ownership of mosquitto pods and MMC pods."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",p({parentName:"pre"},{}),"        sudo chown -R 1000:1000 /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server1/mosquitto/data\n        sudo chown -R 1000:1000 /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server2/mosquitto/data\n        sudo chown -R 1000:1000 /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server3/mosquitto/data\n        sudo chown -R 1000:1000 /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server4/mosquitto/data\n        sudo chown -R 1000:1000 /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server5/mosquitto/data\n        sudo chown -R 1000:1000 /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server6/mosquitto/data\n        sudo chown -R root:root /root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/server1/management-center/config\n"))))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Expose the directories using:\n",(0,a.kt)("inlineCode",{parentName:"p"},"sudo exportfs -a"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Restart the kernel-server\n",(0,a.kt)("inlineCode",{parentName:"p"},"sudo systemctl restart nfs-kernel-server"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},'Install neccessary "nfs-common" library on other nodes so that they act as nfs-clients\n',(0,a.kt)("inlineCode",{parentName:"p"},"sudo apt-get install nfs-common")))))),(0,a.kt)("h2",p({},{id:"installation"}),"Installation"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Prerequisites:")," "),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Kubernetes Cluster should be up and running. If you are yet to setup the cluster, refer Kubernetes Cluster setup section ",(0,a.kt)("a",p({parentName:"li"},{href:"#kubernetes-cluster-setup"}),"Kubernetes Cluster Setup"),"."),(0,a.kt)("li",{parentName:"ol"},"You have successfully created the namespace and configmap for your license (i.e ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-license"),")."),(0,a.kt)("li",{parentName:"ol"},"You have configured your NFS Server by exposing the directories.")),(0,a.kt)("h3",p({},{id:"installation-using-helm-charts"}),"Installation using Helm Charts:"),(0,a.kt)("p",null,"Helm charts offer a comprehensive solution for configuring various Kubernetes resources\u2014including stateful sets, deployment templates, services, and service accounts\u2014through a single command, streamlining the deployment process."),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Setup the folder on your Control-Plane Node:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Make sure you have the ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling")," folder on the Control-Plane node."))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Change Directory:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Navigate to the project directory (i.e multi-node-multi-host).\n",(0,a.kt)("inlineCode",{parentName:"li"},"cd mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling/kubernetes/multi-node-multi-host-autoscale/")))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Install Helm Chart:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Use the following ",(0,a.kt)("inlineCode",{parentName:"p"},"helm install")," command to deploy the Mosquitto application on to your OKD cluster. Replace ",(0,a.kt)("inlineCode",{parentName:"p"},"<release-name>")," with the desired name for your Helm release and ",(0,a.kt)("inlineCode",{parentName:"p"},"<namespace>")," with your chosen Kubernetes namespace:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",p({parentName:"pre"},{className:"language-bash"}),"helm install <release-name>  mosquitto-multi-node-multi-host-autoscale-0.1.0.tgz  --set repoPath=<root-path-to-kubernetes-folder>  --set nfs=<your-nfs-ip> -n <namespace>  --set imageCredentials.registry=registry.cedalo.com --set imageCredentials.username=<username> --set imageCredentials.password=<password> --set imageCredentials.email=<email>\n")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"repoPath"),": Set the ",(0,a.kt)("inlineCode",{parentName:"p"},"repoPath")," flag to the path where the folder ",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling")," resides on NFS server. For eg if it exists on ",(0,a.kt)("inlineCode",{parentName:"p"},"/root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling"),"  therefore the ",(0,a.kt)("inlineCode",{parentName:"p"},"repoPath")," would be ",(0,a.kt)("inlineCode",{parentName:"p"},"/root")," or if exists on ",(0,a.kt)("inlineCode",{parentName:"p"},"/home/demo/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling")," then the ",(0,a.kt)("inlineCode",{parentName:"p"},"repoPath")," would be ",(0,a.kt)("inlineCode",{parentName:"p"},"/home/demo"),".")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"In our case it exists on ",(0,a.kt)("inlineCode",{parentName:"p"},"/root/mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling"),"  therefore the ",(0,a.kt)("inlineCode",{parentName:"p"},"repoPath")," would be ",(0,a.kt)("inlineCode",{parentName:"p"},"/root"),".")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"namespace"),": Set it to the namespace of your deployment.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"Note"),": If you want to deploy the setup in a different namespace other than ",(0,a.kt)("inlineCode",{parentName:"p"},"multinode"),", make sure to pass a separate flag ",(0,a.kt)("inlineCode",{parentName:"p"},"--set namespace=<your-custom-namespace>")," along with the helm installation command.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"Note"),": You need to configure the IP of your NFS server by passing ",(0,a.kt)("inlineCode",{parentName:"p"},"--set nfs=<your-nfs-ip>")," along with the helm installation command. Make sure you use the internal NFS ip accessible from within the Kubernetes cluster and not the external IP exposed to the internet (in case you have one).")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"Note"),": By default the HPA threshold is set to 60 . That mean Horizontal Pod Scaler will scale the pods if overall CPU consumption passes the 60% threshold. To set a new thresold, you can change pass ",(0,a.kt)("inlineCode",{parentName:"p"},"--set hpa_threshold=<new_hpa_threshold>")," along with helm installation command.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"imageCredentials.username"),": Your docker username provided by Cedalo team.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"imageCredentials.password"),": Your docker password provided by Cedalo team.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"imageCredentials.email"),": Registered e-mail for accessing docker registry.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"Note"),": By default the max pod number is set to 5. That means tha HPA can only scale the max replica pods to 5. If you want set a new higher number, you can set it through NFS server IP is set it by passing ",(0,a.kt)("inlineCode",{parentName:"p"},"--set max_replica=<your-max-replica-count>")," by passing it along with helm installation command. Make sure you have configured the servers in HACONFIG and also exported the data directories on NFS server for new potential pods/servers.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"So for eg: If you NFS IP is ",(0,a.kt)("inlineCode",{parentName:"p"},"10.10.10.10"),",",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscaling")," resides at the location  ",(0,a.kt)("inlineCode",{parentName:"p"},"/root")," on your nfs, your name namespace is ",(0,a.kt)("inlineCode",{parentName:"p"},"test-namespace")," ,",(0,a.kt)("inlineCode",{parentName:"p"},"username"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"password")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"email")," be ",(0,a.kt)("inlineCode",{parentName:"p"},"demo-username"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"demo-password")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"demo@gmail.com"),", your new hpa threshold is 80 and max replica changed to 6 your arbitrary release name is ",(0,a.kt)("inlineCode",{parentName:"p"},"sample-release-name")," then your helm installation command should be:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",p({parentName:"pre"},{className:"language-bash"}),"    helm install sample-release-name  mosquitto-multi-node-multi-host-autoscale-0.1.0.tgz    --set repoPath=/root -n test-namespace --set namespace=test-namespace --set nfs=10.10.10.10  --set hpa_threshold=80  --set max_replica=6 --set imageCredentials.registry=registry.cedalo.com --set imageCredentials.username=demo-username --set imageCredentials.password=demo-password --set imageCredentials.email=demo@gmail.com\n"))))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"You can monitor the running pods using the following command:\n",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl get pods -o wide -n <namespace>"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"To uninstall the setup:\n",(0,a.kt)("inlineCode",{parentName:"p"},"helm uninstall <release-name> -n <namespace>")))),(0,a.kt)("p",null,"Your Mosquitto setup is now running  with three single mosquitto nodes and the Management Center.\nTo finish the cluster setup, the Management Center offers a UI to create the Mosquitto HA Cluster. The Management Center is reachable from the localhost via port 31021."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"To set up the cluster follow ",(0,a.kt)("a",p({parentName:"li"},{href:"#create-cluster-in-management-center"}),"these steps"),".")),(0,a.kt)("h3",p({},{id:"further-useful-commands"}),"Further Useful Commands:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"If you want to change mosquitto.conf, you can do so by uncompressing the helm chart, making the required changes and packaging the helm charts again. The detailed procedure is mentioned below:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"tar -xzvf mosquitto-multi-node-multi-host-autoscale-0.1.0.tgz")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cd mosquitto-multi-node-multi-host-autoscale/files/")),(0,a.kt)("li",{parentName:"ul"},"Make changes to ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto.conf")," and save it."),(0,a.kt)("li",{parentName:"ul"},"Go back to the parent directory: ",(0,a.kt)("inlineCode",{parentName:"li"},"cd ../")),(0,a.kt)("li",{parentName:"ul"},"Package the helm chart to its original form using:\n",(0,a.kt)("inlineCode",{parentName:"li"},"helm package mosquitto-multi-node-multi-host-autoscale")),(0,a.kt)("li",{parentName:"ul"},"Uninstall helm package\n",(0,a.kt)("inlineCode",{parentName:"li"},"helm uninstall <release-name> -n <namespace>")),(0,a.kt)("li",{parentName:"ul"},"Reinstall the helm package using the same command you used the first time from the ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.8-mmc-2.8-cluster-kubernetes-autoscale/kubernetes/multi-node-multi-host/")," directory.")))),(0,a.kt)("h2",p({},{id:"create-cluster-in-management-center"}),"Create Cluster in Management Center"),(0,a.kt)("p",null,"After you have completed the installation process, the last step is to configure the Mosquitto HA cluster.\nAccess the Management Center and use the default credentials ",(0,a.kt)("inlineCode",{parentName:"p"},"cedalo")," and password ",(0,a.kt)("inlineCode",{parentName:"p"},"mmcisawesome"),"."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Make sure all three mosquitto nodes are connected in the connection menu. The HA proxy will only connect after the cluster is successfully set up."),(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Cluster Management")," and click ",(0,a.kt)("inlineCode",{parentName:"li"},"NEW CLUSTER"),"."),(0,a.kt)("li",{parentName:"ul"},"Configure ",(0,a.kt)("inlineCode",{parentName:"li"},"Name"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"Description")," and choose between ",(0,a.kt)("inlineCode",{parentName:"li"},"Full-sync")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"Dynamic Security Sync"),"."),(0,a.kt)("li",{parentName:"ul"},"Configure IP address: Instead of private IP address we will DNS address.",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"For node1: ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-0.mosquitto.multinode.svc.cluster.local")," and select broker2 from drop-down"),(0,a.kt)("li",{parentName:"ul"},"For node2: ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-1.mosquitto.multinode.svc.cluster.local")," and select broker2 from drop-down"),(0,a.kt)("li",{parentName:"ul"},"For node3: ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.mosquitto.multinode.svc.cluster.local")," and select broker3 from drop-down"),(0,a.kt)("li",{parentName:"ul"},'Replace "multinode" with your own namespace. If you have used the default one, use the mentioned configurations.'),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-0")," has to be mapped to the mosquitto-1 node in the MMC UI and so on."))),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Save"))),(0,a.kt)("h2",p({},{id:"connect-to-cluster"}),"Connect to cluster"),(0,a.kt)("p",null,'After the creation of the cluster, you can now select the cluster leader in the drop-down in the top right side of the MMC. This is needed, because only the leader is able to configure the cluster. The drop-down appears as soon as you are in one of the broker menus.\nGo to the "Client" menu and create a new client to connect from. Make sure to assign a role, like the default "client" role, to allow your client to publish and/or subscribe to topics.'),(0,a.kt)("p",null,"Now you can connect to the Mosquitto cluster. You can access it either with connecting it directly to worker node running the haproxy pod along with a service exposed at port 31028: "),(0,a.kt)("p",null,"In this example command we use Mosquitto Sub to subscribe onto all topics:\n",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto_sub -h <ip-of-the-worker-node-running-haproxy> -p 31028 -u <username> -P <password> -t '#'")),(0,a.kt)("p",null,"or if you have an load balancer in front of it redirecting the traffic to HAproxy the we can use the ip of the load balancer (mostly for the setup running on Cloud VMs):\n",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto_sub -h <ip-of-the-load-balancer-running-haproxy> -p 31028 -u <username> -P <password> -t '#'"),"\nMake sure to replace your IP, username and password."),(0,a.kt)("h2",p({},{id:"usage"}),"Usage"),(0,a.kt)("p",null,"Once the installation is complete, you can start using the multi-node Mosquitto broker. Be sure to check the Mosquitto documentation for further details on configuring and using the broker."))}f.isMDXComponent=!0}}]);